## Glossary

* **Diagnostics** – A diagnostic is a comparison of a model variable or some combination of model variables with a reference dataset or an intercomparison across models of a model variable or some combination of model variables.
    A diagnostic may also represent an evaluation of a relationship between multiple model variables and/or multiple reference datasets (i.e., Relationship Diagnostics).
    A diagnostic consists of one or more model performance metrics ([Hoffman et al. 2025](https://doi.org/10.5194/egusphere-2025-2685)).
* **Metrics** – A metric is a single statistical evaluation contained within a diagnostic.
    A diagnostic may consist of more than one metric.
    Examples include bias, root mean squared error (RMSE), spatial or temporal correlations (Taylor 2021).
    Not all metrics are useful for all variables or should be used with every observationally constrained dataset.
    Each metric may be evaluated to produce a metric scalar ([Hoffman et al. 2025](https://doi.org/10.5194/egusphere-2025-2685)).
* **Model Evaluation** - Evaluation is the process of assessing simulations against observations;
    the necessity for observations means it can only be done for the historical period,
    and only for variables or processes for which observations or reanalysis data are available.
    Model evaluation can be done for a single model or in a multi-model context ([Hassler et al. 2025](https://doi.org/10.22541/essoar.174196646.65056548/v1)).
* **Validation** – Validation is the process of determining the degree to which a model accurately represents processes in the real world, particularly for the intended uses of the model.
    Validation can include a broad range of aspects from ensuring correct units and the sign of the data produced,
    to the interactions between model components or variables and process representations ([Hoffman et al. 2025](https://doi.org/10.5194/egusphere-2025-2685)).
