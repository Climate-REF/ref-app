The Rapid Evaluation Framework (REF) provides diagnostics to characterise climate model performance
and highlight model spread, diversity and differences. These results may help researchers identify models
suitable for specific applications but should not be interpreted as identifying “good” or “bad” models.
This version 1 release of the REF serves as a starting point for deeper exploration and investigation into
CMIP6 and CMIP6Plus model output.

Community experience in the use of similar calculations suggests that REF outputs are most informative
when users:

* Consider multiple diagnostics and metrics.
* Match evaluation metrics to specific applications or region of interest.
* Account for internal climate variability, model and observational uncertainties.
* Document methodology and selection criteria used in a transparent manner for reproducibility.
* Be aware of any limitations of models and the REF diagnostics in relation to your application.

Containerised version installation: [https://climate-ref.readthedocs.io/]()

Find out more about the forthcoming [version 2 release: CMIP7 Assessment Fast Track](https://wcrp-cmip.org/cmip-phases/cmip7/rapid-evaluation-framework/ )
